word <- words[i]
p.interest <- sum(interest.words==word)/length(interest.words)
p.non.interest <-  sum(non.interest.words==word) /
length(non.interest.words)
odds.ratio <- p.interest/(1-p.interest)
odds.ratio <- odds.ratio / (p.non.interest/(1-p.non.interest))
log.odds.ratio[i] <- log(odds.ratio)
se[i] <-
1/sum(interest.words == word) +
1/sum(interest.words != word) +
1/sum(non.interest.words == word) +
1/sum(non.interest.words != word)
se[i] <- sqrt(se[i])
}
top.words.data <- data.frame(words=words, log.odds.ratio=log.odds.ratio,
se=se)
top.words.data$words <-
factor(top.words.data$words, levels=rev(top.words.data$words))
limits <- aes(ymax = log.odds.ratio + 1.96*se, ymin=log.odds.ratio - 1.96*se)
dodge <- position_dodge(width=0.9)
ggplot(top.words.data, aes(x=words,y=log.odds.ratio)) +
geom_bar(stat="identity") +
theme(text = element_text(size=20),
axis.text.x = element_text(angle = 90, hjust = 1)) +
geom_errorbar(limits, position=dodge, width=0.25, col="red") +
geom_point(col="red", size=3) +
labs(
x=sprintf("top %i %snon-uninteresting words (in order of use)", n.words, words.author),
y=sprintf("log odds ratio of %suse vs rest use", use.author),
title=sprintf("Use of Non-Uninteresting Words in %i Authorship-Undisputed Federalist Papers",
length(undisputed))
) + coord_flip()
grelp("kind", fed.papers[[1]])
grepl("kind", fed.papers[[1]])
lapply(fed.papers, function(x){grepl("kind", x)})
lapply(fed.papers[undisputed], function(x){grepl("kind", x)})
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("kind", x)})
test.kind
fed.papers[undisputed[1]]
test.kind
fed.papers[undisputed[1]]
fed.papers[undisputed[1]][[1]]
fed.papers[undisputed[1]][[1]]
fed.papers[undisputed[1]]
fed.papers[[undisputed[1]]]
fed.papers[[undisputed[1]]][[1]]
strsplit(fed.papers[[undisputed[1]]][[1]],"kind")
test.kind[1:5]
strsplit(fed.papers[[undisputed[2]]][[1]],"kind")
fed.papers[[undisputed[2]]][[1]]
fed.papers[[undisputed[2]]][[17]]
strsplit(fed.papers[[undisputed[2]]][[17]], "kind")
i<-2
essay.num <- undisputed[i]
words <- unlist(fed.papers[[essay.num]])
words <- tolower(words)
words <- gsub("[[:punct:]]", " ", words)
words <- unlist(strsplit(words, " "))
words <- words[!words == ""]
words <- words[!words == " "]
words
which(words == "kind")
which(words == "commercial")
which(words == "kindled")
ham.words <- NULL
mad.words <- NULL
jay.words <- NULL
all.words <- NULL
# Compile all words
n.word.per.essay.2 <- rep(0,length(undisputed))
for (i in 1:length(undisputed)) {
essay.num <- undisputed[i]
words <- unlist(fed.papers[[essay.num]])
words <- tolower(words)
words <- gsub("[[:punct:]]", " ", words)
words <- unlist(strsplit(words, " "))
words <- words[!words == ""]
words <- words[!words == " "]
if (is.element(i, hamilton.index))
ham.words <- c(ham.words, words)
if (is.element(i, madison.index))
mad.words <- c(mad.words, words)
if (is.element(i, jay.index))
jay.words <- c(jay.words, words)
n.word.per.essay.2[i] <- length(words)
all.words <- c(all.words, words)
}
# Sanity check number of words per essay
stopifnot(all(n.word.per.essay.2 == n.word.per.essay))
rm(n.word.per.essay.2)
stopifnot(all(
c(length(ham.words), length(jay.words), length(mad.words))
== tapply(n.word.per.essay, authors, sum)
))
# Compute frequencies
ham.freq <- sort(table(ham.words), decreasing=TRUE)
n.words.ham <- sum(ham.freq)
ham.freq <- ham.freq/n.words.ham
mad.freq <- sort(table(mad.words), decreasing=TRUE)
n.words.mad <- sum(mad.freq)
mad.freq <- mad.freq/n.words.mad
jay.freq <- sort(table(jay.words), decreasing=TRUE)
n.words.jay <- sum(jay.freq)
jay.freq <- jay.freq/n.words.jay
all.freq <- sort(table(all.words), decreasing=TRUE)
n.words.all <- sum(all.freq)
all.freq <- all.freq/n.words.all
#
# Figure out which words were used by each author
#
ham.words <- NULL
mad.words <- NULL
jay.words <- NULL
all.words <- NULL
# Compile all words
n.word.per.essay.2 <- rep(0,length(undisputed))
for (i in 1:length(undisputed)) {
essay.num <- undisputed[i]
words <- unlist(fed.papers[[essay.num]])
words <- tolower(words)
words <- gsub("[[:punct:]]", " ", words)
words <- unlist(strsplit(words, " "))
words <- words[!words == ""]
words <- words[!words == " "]
if (is.element(i, hamilton.index))
ham.words <- c(ham.words, words)
if (is.element(i, madison.index))
mad.words <- c(mad.words, words)
if (is.element(i, jay.index))
jay.words <- c(jay.words, words)
n.word.per.essay.2[i] <- length(words)
all.words <- c(all.words, words)
}
# Sanity check number of words per essay
stopifnot(all(n.word.per.essay.2 == n.word.per.essay))
rm(n.word.per.essay.2)
stopifnot(all(
c(length(ham.words), length(jay.words), length(mad.words))
== tapply(n.word.per.essay, authors, sum)
))
# Compute frequencies
ham.freq <- sort(table(ham.words), decreasing=TRUE)
n.words.ham <- sum(ham.freq)
ham.freq <- ham.freq/n.words.ham
mad.freq <- sort(table(mad.words), decreasing=TRUE)
n.words.mad <- sum(mad.freq)
mad.freq <- mad.freq/n.words.mad
jay.freq <- sort(table(jay.words), decreasing=TRUE)
n.words.jay <- sum(jay.freq)
jay.freq <- jay.freq/n.words.jay
all.freq <- sort(table(all.words), decreasing=TRUE)
n.words.all <- sum(all.freq)
all.freq <- all.freq/n.words.all
ham.words[1:100]
ham.feq[1:100]
ham.freq[1:100]
# Create list of "uninteresting" words.  Some judgement calls here.  Have to
# also consider those words I left in, like "we"
uninteresting.words <-
c("the", "of", "to", "and", "in", "a", "be", "that", "it", "is", "by",
"which", "as", "on", "have", "for", "not", "this", "will", "their",
"or", "with", "are", "been", "from", "they", "may", "an", "would", "other",
"has", "its", "these", "them", "than", "so", "such", "if", "any", "at",
"into", "was", "had", "were", "who", "those", "each", "but", "upon",
"only", "too", "when", "though", "much", "even", "also", "therefore",
"very", "what", "without",
# Dicier words to remove. Focus in on topics/subjects/themes
"we", "all", "no", "more", "most", "his", "he", "either", "there",
"can", "most", "every", "under", "could", "some")
mad.freq <- mad.freq[!is.element(names(mad.freq), uninteresting.words)]
ham.freq <- ham.freq[!is.element(names(ham.freq), uninteresting.words)]
jay.freq <- jay.freq[!is.element(names(jay.freq), uninteresting.words)]
all.freq <- all.freq[!is.element(names(all.freq), uninteresting.words)]
ham.freq[1:100]
ham.words
which(ham.words=="kind")
ham.words[1635:1640]
ham.words[(i-5):(i+5)]
i<- 2800
ham.words[(i-5):(i+5)]
i<- 5002
ham.words[(i-5):(i+5)]
i<- 9090
ham.words[(i-5):(i+5)]
i<- 9144
ham.words[(i-5):(i+5)]
for (i in which(ham.words=="kind"))
{print(ham.words[(i-5):(i+5)])}
which(ham.words=="kindled")
test.kind <- lapply(fed.papers[undisputed], function(x){grepl(" kind ", x)})
test.kind
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("kind", x)})
test.kind
fed.papers[[undisputed[69]]][6]
fed.papers[[undisputed[60]]][19]
sum(ham.words=="mankind")
sum(ham.words=="kind")
sum(ham.words=="kind")
fed.papers[[undisputed[56]]][2]
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("kind of", x)})
test.kind
lapply(test.kind, any)
unlist(lapply(test.kind, any))
which(unlist(lapply(test.kind, any)))
authors(which(unlist(lapply(test.kind, any))))
authors[which(unlist(lapply(test.kind, any)))]
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("this kind", x)})
authors[which(unlist(lapply(test.kind, any)))]
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("kind", x)})
authors[which(unlist(lapply(test.kind, any)))]
test.kind
?lgrep
?grepl
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("kind", fixed=TRUE, x)})
authors[which(unlist(lapply(test.kind, any)))]
test.kind
which(authors=="Madison")
fed.papers[[undisputed[52]]][6]
strsplit(fed.papers[[undisputed[52]]][6], "kind")
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("kind", fixed=TRUE, x)})
test.kind
strsplit(fed.papers[[52]][6], "kind")
fed.papers[[undisputed[52]]][6]
strsplit(fed.papers[[52]][6], "subsists")
strsplit(fed.papers[[52]][[6]], "subsists")
strsplit(fed.papers[[52]][[6]], "kind")
strsplit(fed.papers[[52]][[6]], "to")
strsplit(fed.papers[[52]][[6]], "")
test.kind
fed.papers[[undisputed[69]]][6]
fed.papers[[undisputed[52]]][[7]]
strsplit(fed.papers[[undisputed[52]]][[7]], "kind")
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("this kind", x)})
authors[which(unlist(lapply(test.kind, any)))]
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("kind", x)})
authors[which(unlist(lapply(test.kind, any)))]
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("a kind", x)})
authors[which(unlist(lapply(test.kind, any)))]
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("kind of", x)})
authors[which(unlist(lapply(test.kind, any)))]
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("kind of", x)})
authors[which(unlist(lapply(test.kind, any)))]
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("this kind", x)})
authors[which(unlist(lapply(test.kind, any)))]
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("a kind", x)})
authors[which(unlist(lapply(test.kind, any)))]
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("kind", x)})
test.kind
which(test.kind)
lapply(test.kind, function(x){any(unlist(x))}
)
lapply(test.kind, function(x){any(unlist(x))})
unlist(lapply(test.kind, function(x){any(unlist(x))}))
test.kind
test.kind <- lapply(fed.papers[undisputed], function(x){grepl(" kind ", x)})
test.kind
authors[which(unlist(lapply(test.kind, any)))]
test.kind <- lapply(fed.papers[undisputed], function(x){grepl(" kind ", x)})
authors[which(unlist(lapply(test.kind, any)))]
test.kind
test.kind[[13]]
which(test.kind[[13]])
fed.papers[[undisputed[13]]][which(test.kind[[13]])]
authors[which(unlist(lapply(test.kind, any)))]
which(unlist(lapply(test.kind, any)))
fed.papers[[undisputed[5]]][which(test.kind[[5]])]
which(unlist(lapply(test.kind, any)))
fed.papers[[undisputed[6]]][which(test.kind[[6]])]
which(unlist(lapply(test.kind, any)))
i <- 7
fed.papers[[undisputed[i]]][which(test.kind[[i]])]
which(unlist(lapply(test.kind, any)))
i <- 9
fed.papers[[undisputed[i]]][which(test.kind[[i]])]
i <- 9
fed.papers[[undisputed[i]]][which(test.kind[[i]])][[1]]
strplit(fed.papers[[undisputed[i]]][which(test.kind[[i]])][[1]], "kind")
strsplit(fed.papers[[undisputed[i]]][which(test.kind[[i]])][[1]], "kind")
disputed
authors.array
authors.array[disputed,]
i <- 9
fed.papers[[undisputed[i]]][which(test.kind[[i]])]
which(unlist(lapply(test.kind, any)))
i <- 11
fed.papers[[undisputed[i]]][which(test.kind[[i]])]
test.kind <- lapply(fed.papers[undisputed], function(x){grepl("a kind of", x)})
authors[which(unlist(lapply(test.kind, any)))]
source("./analysis.R")
fed.papers[[1]]
fed.papers[[11]]
source("./analysis.R")
ls()
rm(list=ls())
load("federalist.RData")
ls()
fed.papers[[1]]
unlist(fed.papers[[1]])
unlist(unlist(fed.papers[[1]]))
length(unlist(fed.papers[[1]]))
unlist(fed.papers[[1]])
unlist(fed.papers[[1]])[[1]]
fed.papers[[1]][[1]]
fed.papers[[1]][[1]]
strsplit(fed.papers[[1]][[1]], " ")
tolower(strsplit(fed.papers[[1]][[1]], " "))
strsplit(fed.papers[[1]][[1]], " ")
strsplit(tolower(fed.papers[[1]][[1]]), " ")
tolower(strsplit(fed.papers[[1]][[1]], " "))
strsplit(tolower(fed.papers[[1]][[1]]), " ")
a <- strsplit(tolower(fed.papers[[1]][[1]]), " ")
lapply(fed.papers[[1]], function(x){strsplit(tolower(x), " ")})
unlist(lapply(fed.papers[[1]], function(x){strsplit(tolower(x), " ")}))
table(unlist(lapply(fed.papers[[1]], function(x){strsplit(tolower(x), " ")})))
sort(table(unlist(lapply(fed.papers[[1]], function(x){strsplit(tolower(x), " ")}))))
sort(table(unlist(lapply(fed.papers, function(x){strsplit(tolower(x), " ")}))))
a <- sort(table(unlist(lapply(fed.papers, function(x){strsplit(tolower(x), " ")}))))
length(a)
a <- sort(table(unlist(lapply(fed.papers, function(x){strsplit(tolower(x), " ")}))), decreasing=TRUE)
a[1:100]
p1<- 0.2
p1/p2
p2<-0.5
p1/p2
(p1/(1-p1))/(p2/(1-p2))
p1
p2
p1 <- 0.2
p2 <- 0.4
p1/p2
(p1/(1-p1))/(p2/(1-p2))
p1 <- 0.4
p2 <- 0.8
p1/p2
(p1/(1-p1))/(p2/(1-p2))
p1 <- 0.1
p2 <- p1*2
p1/p2
(p1/(1-p1))/(p2/(1-p2))
log(p1/(1-p1))/(p2/(1-p2)))
logit
p1 <- 0.1
p2 <- p1*2
log(p1/p2)
log((p1/(1-p1))/(p2/(1-p2))))
log((p1/(1-p1))/(p2/(1-p2)))
p1 <- 0.01
p2 <- p1*2
log(p1/p2)
log((p1/(1-p1))/(p2/(1-p2)))
p1 <- 0.4
p2 <- p1*2
log(p1/p2)
log((p1/(1-p1))/(p2/(1-p2)))
p1 <- 0.000000001
p2 <- p1*2
log(p1/p2)
log((p1/(1-p1))/(p2/(1-p2)))
p1 <- 0.49
p2 <- p1*2
log(p1/p2)
log((p1/(1-p1))/(p2/(1-p2)))
extendedstopwords<-c("a","about","above","across","after","again","against","all","almost","alone","along","already","also","although","always","am","among","an","and","another","any","anybody","anyone","anything","anywhere","are","area","areas","aren't","around","as","ask","asked","asking","asks","at","away","b","back","backed","backing","backs","be","became","because","become","becomes","been","before","began","behind","being","beings","below","best","better","between","big","both","but","by","c","came","can","cannot","can't","case","cases","certain","certainly","clear","clearly","come","could","couldn't","d","did","didn't","differ","different","differently","do","does","doesn't","doing","done","don't","down","downed","downing","downs","during","e","each","early","either","end","ended","ending","ends","enough","even","evenly","ever","every","everybody","everyone","everything","everywhere","f","face","faces","fact","facts","far","felt","few","find","finds","first","for","four","from","full","fully","further","furthered","furthering","furthers","g","gave","general","generally","get","gets","give","given","gives","go","going","good","goods","got","great","greater","greatest","group","grouped","grouping","groups","h","had","hadn't","has","hasn't","have","haven't","having","he","he'd","he'll","her","here","here's","hers","herself","he's","high","higher","highest","him","himself","his","how","however","how's","i","i'd","if","i'll","i'm","important","in","interest","interested","interesting","interests","into","is","isn't","it","its","it's","itself","i've","j","just","k","keep","keeps","kind","knew","know","known","knows","l","large","largely","last","later","latest","least","less","let","lets","let's","like","likely","long","longer","longest","m","made","make","making","man","many","may","me","member","members","men","might","more","most","mostly","mr","mrs","much","must","mustn't","my","myself","n","necessary","need","needed","needing","needs","never","new","newer","newest","next","no","nobody","non","noone","nor","not","nothing","now","nowhere","number","numbers","o","of","off","often","old","older","oldest","on","once","one","only","open","opened","opening","opens","or","order","ordered","ordering","orders","other","others","ought","our","ours","ourselves","out","over","own","p","part","parted","parting","parts","per","perhaps","place","places","point","pointed","pointing","points","possible","present","presented","presenting","presents","problem","problems","put","puts","q","quite","r","rather","really","right","room","rooms","s","said","same","saw","say","says","second","seconds","see","seem","seemed","seeming","seems","sees","several","shall","shan't","she","she'd","she'll","she's","should","shouldn't","show","showed","showing","shows","side","sides","since","small","smaller","smallest","so","some","somebody","someone","something","somewhere","state","states","still","such","sure","t","take","taken","than","that","that's","the","their","theirs","them","themselves","then","there","therefore","there's","these","they","they'd","they'll","they're","they've","thing","things","think","thinks","this","those","though","thought","thoughts","three","through","thus","to","today","together","too","took","toward","turn","turned","turning","turns","two","u","under","until","up","upon","us","use","used","uses","v","very","w","want","wanted","wanting","wants","was","wasn't","way","ways","we","we'd","well","we'll","wells","went","were","we're","weren't","we've","what","what's","when","when's","where","where's","whether","which","while","who","whole","whom","who's","whose","why","why's","will","with","within","without","won't","work","worked","working","works","would","wouldn't","x","y","year","years","yes","yet","you","you'd","you'll","young","younger","youngest","your","you're","yours","yourself","yourselves","you've","z")
extendedstopwords <- c(extendedstopwords,
gsub("'","",grep("'",extendedstopwords,value=T)) )
extendedstopwords
require(tm)
require(topicmodels)
install.packages("tm")
install.packages("topicmodels")
dfTranscripts <- read.table("data/transcripts.csv",header=F,sep="\t",colClasses=c("character","character"),col.names=c("url","text"),quote="")
dfTranscripts$comicnumber <- sapply(dfTranscripts$url, function(x) strsplit(x,"/")[[1]][4])
###
setwd("~/Documents/Projects/xkcd-Topics")
dfTranscripts <- read.table("data/transcripts.csv",header=F,sep="\t",colClasses=c("character","character"),col.names=c("url","text"),quote="")
dfTranscripts$comicnumber <- sapply(dfTranscripts$url, function(x) strsplit(x,"/")[[1]][4])
#### Text Cleaning ####
#Remove alt-text (optional)
dfTranscripts$text <- gsub("\\{\\{.*\\}\\}","",dfTranscripts$text)
#Remove scene-description.
#This might initially seem like a bad idea, but scne descriptions contain stuff like [[Man standing in a room]] ,etc.
#I'll revisit this, to see if there's a better solution
dfTranscripts$text <- gsub("\\[\\[.*?\\]\\]","",dfTranscripts$text)
#remove speaker id
#for each pipe-surrounded string, check if there is a : there. If there is, discard the part before the first :
#this is only moderately accurate, but it's the best way I could think of, without manual intervention
RemoveSpeakers <- function(trans){
trans <- paste0("|",trans,"|")
frames <- strsplit(trans,"\\|")[[1]]
processed.frames <- sapply(frames[grep("\\:",frames)],
function(f) {
dialogue<-strsplit(f,":")[[1]]
do.call(paste,as.list(c(
dialogue[2:length(dialogue)],sep="\\:")
))
})
frames[grep("\\:",frames)] <- processed.frames
do.call(paste,as.list(c(frames,sep="|")))
}
dfTranscripts$text <- sapply(dfTranscripts$text,RemoveSpeakers)
#### Create dtm ####
source('scripts/extendedStopwords.R')
source('scripts/extendedStopwords.R')
dtm.control <- list(
tolower 			= T,
removePunctuation 	= T,
removeNumbers 		= T,
stopwords 			= c(stopwords("english"),extendedstopwords),
stemming 			= T,
wordLengths 		= c(3,Inf),
weighting 			= weightTf
)
dtm <- DocumentTermMatrix(Corpus(VectorSource(dfTranscripts$text)),
control = dtm.control)
dim(dtm)
dtm <- removeSparseTerms(dtm,0.999)
dim(dtm)
# Drop documents with little or no text (left)
dtm <- dtm[rowSums(as.matrix(dtm))>0,]
require(tm)
require(topicmodels)
dtm <- DocumentTermMatrix(Corpus(VectorSource(dfTranscripts$text)),
control = dtm.control)
dim(dtm)
dtm <- removeSparseTerms(dtm,0.999)
dim(dtm)
dtm.control <- list(
tolower 			= T,
removePunctuation 	= T,
removeNumbers 		= T,
stopwords 			= c(stopwords("english"),extendedstopwords),
stemming 			= T,
wordLengths 		= c(3,Inf),
weighting 			= weightTf
)
dtm.control
dim(dtm)
dtm <- DocumentTermMatrix(Corpus(VectorSource(dfTranscripts$text)),
control = dtm.control)
dim(dtm)
#### Create dtm ####
source('scripts/extendedStopwords.R')
dtm.control <- list(
tolower 			= T,
removePunctuation 	= T,
removeNumbers 		= T,
stopwords 			= c(stopwords("english"),extendedstopwords),
stemming 			= T,
wordLengths 		= c(3,Inf),
weighting 			= weightTf
)
dtm <- DocumentTermMatrix(Corpus(VectorSource(dfTranscripts$text)),
control = dtm.control)
dim(dtm)
dtm <- removeSparseTerms(dtm,0.999)
dim(dtm)
require(tm)
require(topicmodels)
dfTranscripts <- read.table("data/transcripts.csv",header=F,sep="\t",colClasses=c("character","character"),col.names=c("url","text"),quote="")
dfTranscripts$comicnumber <- sapply(dfTranscripts$url, function(x) strsplit(x,"/")[[1]][4])
#### Text Cleaning ####
#Remove alt-text (optional)
dfTranscripts$text <- gsub("\\{\\{.*\\}\\}","",dfTranscripts$text)
#Remove scene-description.
#This might initially seem like a bad idea, but scne descriptions contain stuff like [[Man standing in a room]] ,etc.
#I'll revisit this, to see if there's a better solution
dfTranscripts$text <- gsub("\\[\\[.*?\\]\\]","",dfTranscripts$text)
#remove speaker id
#for each pipe-surrounded string, check if there is a : there. If there is, discard the part before the first :
#this is only moderately accurate, but it's the best way I could think of, without manual intervention
RemoveSpeakers <- function(trans){
trans <- paste0("|",trans,"|")
frames <- strsplit(trans,"\\|")[[1]]
processed.frames <- sapply(frames[grep("\\:",frames)],
function(f) {
dialogue<-strsplit(f,":")[[1]]
do.call(paste,as.list(c(
dialogue[2:length(dialogue)],sep="\\:")
))
})
frames[grep("\\:",frames)] <- processed.frames
do.call(paste,as.list(c(frames,sep="|")))
}
dfTranscripts$text <- sapply(dfTranscripts$text,RemoveSpeakers)
#### Create dtm ####
source('scripts/extendedStopwords.R')
dtm.control <- list(
tolower 			= T,
removePunctuation 	= T,
removeNumbers 		= T,
stopwords 			= c(stopwords("english"),extendedstopwords),
stemming 			= T,
wordLengths 		= c(3,Inf),
weighting 			= weightTf
)
dtm <- DocumentTermMatrix(Corpus(VectorSource(dfTranscripts$text)),
control = dtm.control)
?DocumentTermMatrix
ls()
source("./analysis.R")
setwd("~/Documents/Projects/Federalist")
source("./analysis.R")
ls()
length(disputed)
length(undisputed)
setwd("~/Downloads/okcupid-master")
profiles <- read.csv(file="profiles.20120630.csv", header=TRUE)
profiles[56,]
which(substr(names(profiles), 1, 5) == "essay")
essays <- which(substr(names(profiles), 1, 5) == "essay")
profiles[56,essays]
rm(list=ls())
